{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f648ce1f-083d-4174-bf42-a4bdca2b941e",
   "metadata": {},
   "source": [
    "Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c58234-ad97-4dec-b894-207a415c6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb999ff8-0ec9-43b7-855f-3b7d368afe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_path = \"chromedriver.exe\"\n",
    "service = Service(executable_path=chrome_path)\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca41ad4b-f37c-4c5d-a69e-c05125af383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Generic Scraping Function\n",
    "def scrape_website(url, site_name, sleep_time=5):\n",
    "    print(f\" Scraping {site_name}...\")\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    elements = driver.find_elements(By.XPATH, \"//*\")\n",
    "    data = []\n",
    "\n",
    "    for el in elements:\n",
    "        try:\n",
    "            text = el.text.strip()\n",
    "            if text and len(text.split()) <= 20:\n",
    "                data.append(text)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Save scraped data\n",
    "    os.makedirs(\"data/raw\", exist_ok=True)\n",
    "    df = pd.DataFrame({\"text\": list(set(data))})\n",
    "    df.to_csv(f\"data/raw/{site_name.lower()}_raw.csv\", index=False)\n",
    "    print(f\" {site_name} scraping complete! {len(df)} items saved.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8740fe6-dca5-4319-863e-ce6a0de8de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scraping Amazon...\n",
      " Amazon scraping complete! 207 items saved.\n",
      "\n",
      " Scraping Ajio...\n",
      " Ajio scraping complete! 251 items saved.\n",
      "\n",
      " Scraping Nykaa...\n",
      " Nykaa scraping complete! 60 items saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run Scraping for 3 Sites\n",
    "scrape_website(\"https://www.amazon.in\", \"Amazon\")\n",
    "scrape_website(\"https://www.ajio.com\", \"Ajio\")\n",
    "scrape_website(\"https://www.nykaa.com\", \"Nykaa\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a5e3549-cede-4e99-a528-fe959aceed46",
   "metadata": {},
   "source": [
    "Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f469d43-c9d5-467e-8f0d-e2697b60e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to automatically label text based on keywords\n",
    "def auto_label(text):\n",
    "    promo_keywords = [\n",
    "        \"offer\", \"sale\", \"deal\", \"discount\", \"off\", \"upto\", \"%\", \n",
    "        \"limited time\", \"save\", \"lowest price\", \"exclusive\"\n",
    "    ]\n",
    "    text_lower = str(text).lower()\n",
    "    return \"Promotion\" if any(keyword in text_lower for keyword in promo_keywords) else \"Non-Promotion\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f8bc56-8360-4702-a231-867123b9be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_label_site(site_name):\n",
    "    print(f\" Auto-labeling {site_name}...\")\n",
    "    os.makedirs(\"data/labeled\", exist_ok=True)\n",
    "    \n",
    "    # Load raw scraped data\n",
    "    df = pd.read_csv(f\"data/raw/{site_name.lower()}_raw.csv\")\n",
    "    df.dropna(inplace=True)\n",
    "    df = df[df['text'].str.strip() != \"\"]\n",
    "    \n",
    "    # Apply label as text\n",
    "    df['label'] = df['text'].apply(auto_label)\n",
    "    \n",
    "    # Save labeled data\n",
    "    df.to_csv(f\"data/labeled/{site_name.lower()}_labeled.csv\", index=False)\n",
    "    print(f\" Labeled data saved to data/labeled/{site_name.lower()}_labeled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ce91d21-9d29-491f-b270-556d4da2c90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Auto-labeling Amazon...\n",
      " Labeled data saved to data/labeled/amazon_labeled.csv\n",
      " Auto-labeling Ajio...\n",
      " Labeled data saved to data/labeled/ajio_labeled.csv\n",
      " Auto-labeling Nykaa...\n",
      " Labeled data saved to data/labeled/nykaa_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "auto_label_site(\"Amazon\")\n",
    "auto_label_site(\"Ajio\")\n",
    "auto_label_site(\"Nykaa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c768d3-901d-4c08-be68-3abd83a89b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a7ec2f91-942c-4b38-8dc3-e8557db2648b",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71cf2bf1-4964-471d-8c0c-7a740f452633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "#Load Labeled Data\n",
    "df_amazon = pd.read_csv(\"data/labeled/amazon_labeled.csv\")\n",
    "df_ajio = pd.read_csv(\"data/labeled/ajio_labeled.csv\")\n",
    "df_nykaa = pd.read_csv(\"data/labeled/nykaa_labeled.csv\")\n",
    "\n",
    "#Combine all data\n",
    "df = pd.concat([df_amazon, df_ajio, df_nykaa], ignore_index=True)\n",
    "df.dropna(subset=['text', 'label'], inplace=True)\n",
    "df['text'] = df['text'].astype(str)\n",
    "df['label'] = df['label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f919dcaa-ae59-4c42-82a5-d366a3944128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test sets\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words='english', max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe222b1a-b8a0-4e47-a317-56969afdc239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.80        34\n",
      "           1       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.70        56\n",
      "   macro avg       0.77      0.62      0.60        56\n",
      "weighted avg       0.75      0.70      0.65        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train the Classifier\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#Evaluate\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b13fef4a-a069-485d-ab97-f1dfa81990f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved to /models/\n"
     ]
    }
   ],
   "source": [
    "#Save model and vectorizer\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(model, \"models/promotion_classifier.pkl\")\n",
    "joblib.dump(vectorizer, \"models/tfidf_vectorizer.pkl\")\n",
    "print(\"Model and vectorizer saved to /models/\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39018702-58cb-4e17-90cd-7d51c5368392",
   "metadata": {},
   "source": [
    "Inference â€“ Predict Promotions from New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74df6b6a-1ffd-48b3-940f-eb1b9b5d8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load(\"models/promotion_classifier.pkl\")\n",
    "vectorizer = joblib.load(\"models/tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c88aaa4-19c8-41e5-b2f3-44288cb1d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict promotion status\n",
    "def predict_promotion(text):\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    prediction = model.predict(text_vector)[0]\n",
    "    return \" Promotion\" if prediction == 1 else \" Non-Promotion\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff9cc286-2b64-4ba6-98ff-71b696451817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/predicted\", exist_ok=True)\n",
    "\n",
    "#function to predict and save\n",
    "def predict_and_save(site_name):\n",
    "    print(f\"\\n Predicting promotions in {site_name} data...\")\n",
    "    file_path = f\"data/raw/{site_name.lower()}_raw.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.dropna(inplace=True)\n",
    "    df['text'] = df['text'].astype(str)\n",
    "    df['prediction'] = df['text'].apply(predict_promotion)\n",
    "    output_path = f\"data/predicted/{site_name.lower()}_predicted.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\" Predictions saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e564b6-6d63-48e7-baee-868277db9bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Predicting promotions in Amazon data...\n",
      " Predictions saved to data/predicted/amazon_predicted.csv\n",
      "\n",
      " Predicting promotions in Ajio data...\n",
      " Predictions saved to data/predicted/ajio_predicted.csv\n",
      "\n",
      " Predicting promotions in Nykaa data...\n",
      " Predictions saved to data/predicted/nykaa_predicted.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_and_save(\"Amazon\")\n",
    "predict_and_save(\"Ajio\")\n",
    "predict_and_save(\"Nykaa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998ea3a-99d5-445f-946c-0df0140f0c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
